%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%   Find a Nice Title: #Seen #Storytelling #Events   %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{sig-alternate}

\usepackage{url}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{color}
\usepackage{multirow}

% listing styles
\lstset{numbers=left, numberstyle=\tiny,basicstyle=\ttfamily\scriptsize, tabsize=2, keywordstyle=\underbar, stringstyle=\small, backgroundcolor=\color[gray]{0.94}, framexleftmargin=2pt}
\lstdefinestyle{rdfa}{numberblanklines=true, morekeywords={}}

% Turtle box
\definecolor{olivegreen}{rgb}{0.2,0.8,0.5}
\definecolor{grey}{rgb}{0.5,0.5,0.5}
\lstdefinelanguage{ttl}{
sensitive=true,
morecomment=[l][\color{grey}]{@},
morecomment=[l][\color{olivegreen}]{\#},
morestring=[b][\color{blue}]\",
keywordstyle=\color{cyan},
morekeywords={version,owl,rdf,rdfs,xml,xsd,dbpedia,dbo,str,sso,scms,fr,ld}
}
\lstset{
        basicstyle=\ttfamily\scriptsize,
        upquote=true,
        showspaces=false,
        showstringspaces=false,
        showtabs=false,
        tabsize=2,
        frame=none,
        breaklines,
        numbers=none,
        framexleftmargin=2mm,
        xleftmargin=2mm,
}

\newcommand{\hilight}[1]{\colorbox{yellow}{#1}}
\newcommand{\todo}[1]{\colorbox{red}{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  Beginning of document  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Storifying Events with Timelines of Links}

\numberofauthors{3}
\author{
\alignauthor Carlo Andrea Conte\\
	\affaddr{Mahaya Inc.}\\
    \affaddr{New York, USA}\\
    \email{carloante@msn.com}
\alignauthor Rapha\"el Troncy\\
	\affaddr{EURECOM}\\
	\affaddr{Biot, France}\\
	\email{raphael.troncy@eurecom.fr}	\\
\alignauthor Mor Naaman\\
    \affaddr{Cornell Tech and Mahaya, Inc.}\\
    \affaddr{New York, USA}\\
    \email{mor.naaman@cornell.edu}
}

\maketitle

%%%%%%%%%%%%%%%%%%
%%%  Abstract  %%%
%%%%%%%%%%%%%%%%%%

\begin{abstract}
% Motivation: story is being told with links which are being shared. Describe the links processing algorithms, architecture, engineering. Describe the two algorithms that extract links (based on volume, based on velocity).

Social media platforms constitute a valuable source of information regarding real-world happenings. In particular, user generated content on mobile-oriented platforms like Twitter allows for real-time narrations thanks to the instantaneous nature of publishing. A common practice for users is to include in the tweets links to to more exhaustive articles, media files and other resources. In this paper, we are interested in how the resources shared in a stream of Tweets for an event can be analyzed, and how can they help tell the event story. Our system extracts, resolves, and eventually filters the resources shared in the content according to two different ranking functions. 

We are interested in how these different ranking functions perform in the speed and accuracy in which relevant and important resources, that help tell the event story, are discovered. 
\todo{Write conclusions reached}


\end{abstract}

% A category with the (minimum) three required fields
\category{H.3.1}{Information Storage and Retrieval}{Content Analysis and Indexing}
%\terms{Algorithms,Measurement,Experimentation,Web}
\keywords{Event summarization, Content Analysis, Twitter, URLs}

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  1. Introduction  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:introduction}

\todo{Mention real-time and low-latency requirements}

\todo{we mention we only use tweets and why (see comment) -- no need to elaborate; mentioned in intro (MN)}
% The reason why only tweets are taken into account is that Twitter includes in every tweet's data a list of entities. Such list contains a number of meaningful items parsed from the original text. Typical examples include hashtags and, luckily for us, web urls. Another reason for this choice is that users are more likely to publish links via Twitter than via Instagram, as the latter is a service strongly centered on content creation.

\todo{Mention we don't cover the logic for gathering tweets (see comment) -- added short comment to intro, need to say one sentence in relevant section (MN)}
%...as we build our experiment on top of Seen's constantly updated database. \cite Wired's article about Seen

\todo{Also mention we don't cover logic for general event metadata, we use Seen's db -- one sentence in relevant section will suffice (MN)}

% -How people talk on Twitter about events
% -Problem of noise, quantity, quality
% -Problem of real-time computation
% -Introducing paper's sections

For many events and real-world happenings, Twitter, Facebook, Instagram, and other social media platforms provide a continuous stream of user-contributed messages and media. Very often, the messages posted includes hyperlinks to content outside the platform where the message was posted. The nature of these resources addressed via the hyperlink are varied: they may point to images, news articles, real-time video streams and many other types of content. Our goal is to identify resources shared via hyperlinks in social media streams that are \emph{highly relevant} and \emph{important} to an ongoing event, given a stream of social media about the event. Extracting these relevant resources, and aggregating them in a storyline, can lead to a richer narration of the event thanks to the use of a very diverse set of media.

In this paper, we describe a system that aims at extracting a timeline of resources from a stream of Twitter messages about an event. These resources will be ranked and filtered in close real time, in order to identify relevant, valuable information as soon as possible after it is shared. In addition, the system extracts descriptive metadata from the referenced pages that can be used to represent the resource in the event timeline in an intelligible way. 

Our contributions thus include: a) a general architecture of resource extraction system; and b) the investigation of two scoring methods to extact resources from the stream of event tweets. First, we discuss related research.

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  2. Related Work  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
\label{sec:related-work}

\todo{Raphael, Mor}
First para, like: there has been a lot of work on events, including identify event content (mor's WSDM 2012, others), organizing content from events (...). Here we focus on (what we focus on in this section, maybe extraction of resources, or something more general?)

Second para: A number of projects looked at PROBLEM X. For example,... . These projects are different than ours WHY.

Third para: Other projects addressed PROBLEM Y. For example,... . These projects are different than ours WHY.


%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  3. Architecture  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Architecture}
\label{sec:architecture}
% This section can be shortened, I'll decide when the first draft of the paper is ready and I can see how long it is
In this section we describe the overall architecture for the system that extracts and ranks resources that are linked to in Twitter messages about an event. 

The system we propose needs to run in real time, in order to build storylines of events as they are unfolding. Our goal is to be able to identify key resources with the smallest delay possible. These requirements impose the adoption of an efficient, flexible concurrency process that would be easily scalable according to the data flow. \comment{At the same time, it must be possible to process past events with the same algorithm, as results should be consistent regardless the moment the event takes place.}

For the purpose of this work, we assume our input is a stream of Twitter messages that has been idetified as relavant to the event being tracked. In our case, these streams are genreated by using a hashtag that is associated with each event, but the system described here is agnostic to how the Twitter content is identified. We will assume that a separated process retreives the Twitter content, and keeps updating our database at regular intervals with raw data from Twitter. 

% No need: As mentioned above, we do not cover the interface this system has with the original source of data. 
% NO NEED HERE: In our testing environment, Twitter is queried for contents for a given event about every 15 minutes, although this frequency can significantly fluctuate depending on the number of events being tracked by the system at the same time.  We used a MongoDB database, where raw data was indexed according to creation time and mentioned hashtags.

The different computational steps performed in the resource extraction process are:
\begin{enumerate}
 \item Extracting links from a collection of tweets for an event,
 \item Resolving these links to their canonical form to identify duplicate resources,
 \item Ranking links and applying a first basic filter,
 \item Collecting useful metadata from the pages referenced by the links selected,
 \item Outputting a timeline of links featuring real-time filtering functions.
\end{enumerate}

We now detail the general architecture of this system. Figures \ref{fig:architecture_resolution} and \ref{fig:architecture_metadata} outline the major building blocks of the system.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=6cm]{Figures/links_processing_architecture_resolution.png}
  \caption{Architecture - From extraction to resolution.}
  \label{fig:architecture_resolution}
\end{figure}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=6cm]{Figures/links_processing_architecture_metadata.png}
  \caption{Architecture - From ranking to page scraping.}
  \label{fig:architecture_metadata}
\end{figure}

The complete process for each link implies two very severe bottlenecks: the url resolution and the page scraping. In order to overcome this limitation and build a more efficient system, we split the logic in different parts intended to run in parallel.

The \emph{links dispatcher} (Figure \ref{fig:architecture_resolution}) represents the first step of this processing chain. It retrieves from the \emph{content database} all the tweets for a particular temporal window and containing any of the hashtags included in a given set. After loading the raw data, the links dispatcher extracts every link from the tweets' entities (\cite{RestTweetsDoc}), it queries the \emph{links mappings} class to check if such URL has been resolved already. If it hasn't, it places it in a \emph{links resolutor queue}, otherwise it adds it together with information about its tweet to the \emph{links appearances}. The links dispatcher can be run on happening events, by computing the temporal window's length according to the time of the previous processing, but it can also process past events, by using a sliding window algorithm where the window has a pre-defined size that adjusts itself to handle slow processing cases.

The links resolutor queue is a Redis queue\cite{RedisQueues} of jobs. This means that a list of pointers to python functions and their arguments is stored in a Redis database for later execution. The processes responsible of reading job queues and executing them are called ``workers''. The advantages of this approach resides in the fact that many workers instances can be run at the same time, and their number and behavior can be adjusted according to the workload. This allows for great flexibility in the way the system can be scaled depending on the abundancy of data.

All the urls in the links resolutor queue will be resolved by the \emph{links resolutor} function. This function will first look the url up in the links mappings and, if it is not found, it resolves the url and eventually saves a new mapping. This resolution step is necessary because most links on Twitter are shortened by various url shortener services (sometimes provided by Twitter itself). When a link is successfully resolved, it is added to the \emph{links appearances} and a new mapping is saved.

The \emph{links appearances} class manages an unnormalized collection of all the resolved links. Every item contains information about the url, the tweet that contained it and the event that url was for. In fact, multiple items might carry data about the same combination of url and tweet as long as they reference different events.

Links appearances are periodically accessed by the \emph{decider} (Figure \ref{fig:architecture_metadata}), which is responsible of ranking them and filtering them as needed. The computation is always done on a sliding temporal window of fixed size, and only for links of one event at a time. The scoring system relies on \emph{links score processors} for its decision process: different score processors can be implemented for testing different score functions. We will detail the links score processors used for our experiments in Sections \ref{sec:volume_based_links_selection} and \ref{sec:velocity_based_links_selection}. The LSPs\footnote{Links Score Processors} we will use only implement a very basic first filtering: their main function in the experiments discussed in this paper will consist in enriching the event links with features useful for ranking. More consisten filtering possibilities will be provided by our front-end interface.

If a link is selected for publication, the decider queries the \emph{pages metadata} class for any available metadata for that link. If no metadata is available, the link appearance is added to the \emph{Links Metadata Queue}, otherwise it is saved together with its metadata as an \emph{event link}. The decider can either be run in real time on happening events, or it can simulate the same sliding window algorithm on past events.

The \emph{Links Metadata Queue} is processed by the \emph{metadata scraper}. This function extracts the domain from the url and selects a scraper class accordingly, it loads the referenced page and extracts pieces of information from it (e.g. a title, a description and a representative image). Different scrapers look for different tags in the DOM structure, as different websites usually expose different information in different ways. In our tests, we will use a generic scraper that collects information stored in Open Graph and Twitter Cards meta-tags. Only links for which enough metadata is found are saved as event links while the pages metadata collection is updated accordingly. Event link duplicates are avoided, while their scores and other relevant features are updated to the latest result.

The final results of this system are stored in the event links collection. This dataset holds all the links together with their score and other attributes infered by the link score processor used to rank them (e.g. total volume, highest volume in a time-window duration etc...). In addition to this, the same record contains the metadata extracted from the referenced page and the id of the event for which that link was processed. In fact, the same link can appear multiple times as long as it referenced different events.

\section{Front-end Interface}
\todo{In this section, we discuss sample presentation for extracted resources}

The results of this process will all be displayed on a simple javascript interface, under the form of a storyline: the list of links will be sorted chronologically according to a \emph{display time} field defined by the LSP. A filtering functionality will make it possible to select a cutoff score for the links to be visualized. This interface also draws a pie-chart representing the source domains of the links displayed (taking into account the filtering parameter).

Figure \ref{fig:javascript_interface} shows a very simple example of the storyline.\todo{Screenshot} The attributes shown for every link must be interpreted according to the LSP that produced them, this will be explained after introducing each LSP. It is more clear thanks to this example one reason why our system scrapes information from every page: any visual representation will take advantage of it to make the list more human readable. Moreover, the combination of an image and a description can offer a more complete information than a tweet alone.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=6cm]{Figures/javascript_interface.png}
  \caption{Front-end interface easing the process of extracting and visualizing data.}
  \label{fig:javascript_interface}
\end{figure}

One additional feature implemented by this interface is the aggregation of information regarding the source domain of every item: this attribute is added by the metadata scraping process to every link, and it is included in the HTML structure of the page via data attributes to be read and charted by the javascript application. We will make use of these charts when discussing our tests' results.

\section{Ranking Methods}
\todo{In this section, two methods of ranking...}
Goals of ranking: 1) as early as possible and 2) robust: relevant and important. Not just every link -- not even all relevant links (may be too much). However, when something is relevant and important, identify it as early as possible,  

\subsection{Volume based LSP}
\label{sec:volume_based_links_selection}
Organizing a collection of every single appearance of every link gives us the possibility to obtain information about the volume of shares reached by a link during the event. As an example, Figure \ref{fig:batkid_whitehouse_volume} shows the number of appearances in time of the link to president Obama's Vine for Batkid\footnote{An initiative of Make-A-Wish Foundation for a child affected by leukemia and that attracted the attention of social media: http://abcnews.go.com/US/batkids-make-transforming-san-francisco-gotham/story?id=20899254}.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth]{Figures/batkid_whitehouse_volume.png}
  \caption{Volume of president Obama's Vine video for Batkid shares.}
  \label{fig:batkid_whitehouse_volume}
\end{figure} \todo{Higher time-resolution excel graph}

The volume based LSP assigns to every link a score equal to the cumulative function of its volume throughout the event. A very basic filtering step is implemented by a manually chosen volume threshold that is only meant to exclude the noise of links that did not trigger any interest at all in the audience, and can be considered to be background noise (e.g. those links with only one appearance). Such threshold should be set according to the general volume of an event: we will euristically tune these thresholds after extracting from the database aggregated statistics regarding the volume of these links. 

A link that has been shared at a nearly constant rate during the analyzed time range will be more likely to appear in our timeline than a link that reached a very high volume at a particular point in time. The display time for links ranked by this LSP is choosen to be the time of the earliest appearance that passed the elementary filtering (e.g. the second appearance of a link). Even if the precision of this parameter will suffer from setting very selective volume filters, we are assuming that high-volume events imply a faster growth of the volume of relevant links, thus introducing only smaller delays.

\subsection{Velocity based LSP}
\label{sec:velocity_based_links_selection}
The velocity based LSP computes links' scores as the appearances volume reached by a link within one decider processing time window. The decider's time windows occur every 20 minutes and are 30 minutes long, thus allowing a 10 minutes overlap between each window.

This LSP implements the same filter described in Section \ref{sec:volume_based_links_selection}, with the only difference that the threshold is compared with the current time window's volume. The display time is defined as the first time a link appearance survives the filtering for the first time in a time window. However, the score is always updated to the highest volume the link has reached within a window.

%%%%%%%%%%%%%%%%%%%%%%%%
%%%  4. Experiments  %%%
%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments}
\label{sec:experiment}
In this section we describe the experiments made to evaluate the efficacy of the storylines built using our method, and to compare the results obtained with different LSPs (Sections \ref{sec:volumeResults} and \ref{sec:velocityResults}). In Section \ref{sec:dataset} we clarify what system constitutes the data source for our experiments, as well as how data is structured in such system.
\todo{Add that we also used this data to analyze sources, because can help improving}

\subsection{Notes and ideas to write about experimental results.}
\begin{itemize}
\item Events chose to represent low/medium/high volume events and three different categories (conference,music,breaking news), they are past events, but the processing simulates the same mechanism that acts on happening events.
\item Sources pies
  \begin{itemize}
    \item Highlighted are every time those sources that had more relevance in the particular event (there is no color for NBC news in the TechCrunch event)
    \item Results distorted by broken links and because of Twitter's audience and usage.
    \item Filter steps choosen to better show how the sources composition changes according to the volume requested. Usually, it's more interesting what happens for volumes 1,2,3, as higher numbers don't reveal a statistic anymore, and are distorted by outliers.
  \end{itemize}
\item Volume/Cardinality graph
\begin{itemize}
    \item Green line: true positives, blue line: total
    \item A filter threshold is selected so that a more readable number of items is visible (less than 100).
    \item After filtering by such threshold, false positives that are still visible are selected (This is why plots don't show the true-positives curves for the first values of the series).
    \item Those items that are completely unrelated to the event, and those items that are related to the topic of the event but not to the event itself, are marked as false positives.
    \item ALSO REMOVED CONTENTS (e.g. Instagram pages saying the photo does not exist) are considered false positives.
\end{itemize}
\end{itemize}

\subsection{Dataset}
\label{sec:dataset}
The data used in our experiments is provided by Seen\footnote{http://seen.co}, a service that aims at organizing social media by building automatic summaries of events \cite{SeenWired}. An event can be defined on this system by specifying a set of hashtags and a time range. Once these parameters are known, the contents database (shown in Figure \ref{fig:architecture_resolution}) is constantly updated with new raw data gathered from different social platforms at regular intervals in time, until the end of the event.

Events' metadata is saved to a collection in a different database (the web database' of Figures \ref{fig:architecture_resolution} and \ref{fig:architecture_metadata}). Initially, metadata only comprehends parameters specified by the user, but it is later enriched with meaningful information utomatically inferred by the service. For our software, only the metadata specified by the user is needed to retrieve the right subset of raw contents from the contents database. However we will only select events that already exist on the platform, so that we can first acknowledge the general characteristics of each event in terms of data flow.

\subsection{Volume based LSP experimental results}
\label{sec:volumeResults}

Volume Based LSP produces a better ranking because results' ranking is more sparse. %Examples
Although precision preformances are almost the same in most cases, the TCDisrupt event has a good

\subsection{Velocity based LSP experimental results}
\label{sec:velocityResults}

Velocity based LSP does not rank links as well as the volume based processor (they tend to concentrate in smaller values), and very few links will have incredibly higher values than the mean.

Although, those few outliers with very high values, happened to be, in all our experiments, true positives (they could used as ``highlighted'' links or reccomendations).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  5. Sources Analysis  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Domains (Sources?) Analysis}
\label{sec:sources}
\todo{See evernote note for observations}
Show examples, speculations...
Storylines can be improved according to their category: if a system is trained with the sources profiles for each category, it will be possible to assign different priorities for contents from specific domains/sources. It will also be possible to identify ``official'' sources and similars as outliers not normally present in the patterns used for training.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  6. Conclusion and Future Work  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion and Future Work}
\label{sec:conclusions}
\todo{better Deduplication,.}

\section{Acknowledgments}
\label{sec:ack}

\nocite{*}
\bibliographystyle{abbrv}
\bibliography{seen}
\balancecolumns
% That's all folks!
\end{document} 
